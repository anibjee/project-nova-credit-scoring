{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Nova: EDA and Fairness Analysis\n",
    "\n",
    "This notebook provides exploratory data analysis and fairness evaluation for the Nova Credit Scoring Engine.\n",
    "\n",
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üìä Project Nova - EDA and Fairness Analysis\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated dataset\n",
    "data_path = Path('../data/partners.csv')\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"‚úÖ Dataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    # Load metadata if available\n",
    "    meta_path = Path('../data/metadata.json')\n",
    "    if meta_path.exists():\n",
    "        with open(meta_path) as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"üìã Metadata: {metadata}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found. Please run the data generation first:\")\n",
    "    print(\"   python src/generate_data.py --n 50000 --seed 42 --out data/partners.csv\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üîç Dataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nüìà Basic Statistics:\")\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üéØ Target Variable Distribution:\")\n",
    "    target_dist = df['defaulted_12m'].value_counts()\n",
    "    print(f\"Non-defaulted: {target_dist[0]:,} ({target_dist[0]/len(df)*100:.1f}%)\")\n",
    "    print(f\"Defaulted: {target_dist[1]:,} ({target_dist[1]/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Plot target distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Count plot\n",
    "    sns.countplot(data=df, x='defaulted_12m', ax=axes[0])\n",
    "    axes[0].set_title('Default Distribution (Count)')\n",
    "    axes[0].set_xlabel('Defaulted in 12 months')\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(target_dist.values, labels=['No Default', 'Default'], autopct='%1.1f%%')\n",
    "    axes[1].set_title('Default Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Analyze sensitive attributes\n",
    "    sensitive_attrs = ['gender', 'region', 'role']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, attr in enumerate(sensitive_attrs):\n",
    "        # Distribution by attribute\n",
    "        df[attr].value_counts().plot(kind='bar', ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution by {attr.title()}')\n",
    "        axes[i].set_xlabel(attr.title())\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Age distribution\n",
    "    df['age'].hist(bins=20, ax=axes[3])\n",
    "    axes[3].set_title('Age Distribution')\n",
    "    axes[3].set_xlabel('Age')\n",
    "    axes[3].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Analysis by Sensitive Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Default rates by sensitive attributes\n",
    "    print(\"‚öñÔ∏è Default Rates by Sensitive Attributes:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for attr in sensitive_attrs:\n",
    "        default_rates = df.groupby(attr)['defaulted_12m'].agg(['count', 'mean']).round(4)\n",
    "        default_rates.columns = ['Count', 'Default_Rate']\n",
    "        print(f\"\\n{attr.upper()}:\")\n",
    "        print(default_rates)\n",
    "        \n",
    "        # Statistical test for differences\n",
    "        from scipy.stats import chi2_contingency\n",
    "        contingency = pd.crosstab(df[attr], df['defaulted_12m'])\n",
    "        chi2, p_value, _, _ = chi2_contingency(contingency)\n",
    "        print(f\"Chi-square test p-value: {p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"‚ö†Ô∏è  Significant difference detected!\")\n",
    "        else:\n",
    "            print(\"‚úÖ No significant difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Visualize default rates by sensitive attributes\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for i, attr in enumerate(sensitive_attrs):\n",
    "        default_rates = df.groupby(attr)['defaulted_12m'].mean()\n",
    "        default_rates.plot(kind='bar', ax=axes[i], color='skyblue', edgecolor='black')\n",
    "        axes[i].set_title(f'Default Rate by {attr.title()}')\n",
    "        axes[i].set_xlabel(attr.title())\n",
    "        axes[i].set_ylabel('Default Rate')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for j, v in enumerate(default_rates.values):\n",
    "            axes[i].text(j, v + 0.002, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Key numerical features\n",
    "    key_features = ['earnings_monthly', 'trips_weekly', 'on_time_rate', 'cancel_rate', \n",
    "                   'customer_rating', 'income_volatility', 'tenure_months']\n",
    "    \n",
    "    # Feature distributions by default status\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, feature in enumerate(key_features):\n",
    "        if i < len(axes):\n",
    "            # Box plot by default status\n",
    "            sns.boxplot(data=df, x='defaulted_12m', y=feature, ax=axes[i])\n",
    "            axes[i].set_title(f'{feature.replace(\"_\", \" \").title()} by Default Status')\n",
    "            axes[i].set_xlabel('Defaulted')\n",
    "    \n",
    "    # Remove unused subplot\n",
    "    if len(key_features) < len(axes):\n",
    "        fig.delaxes(axes[-1])\n",
    "        fig.delaxes(axes[-2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Correlation analysis\n",
    "    print(\"üîó Feature Correlations with Default:\")\n",
    "    correlations = df[key_features + ['defaulted_12m']].corr()['defaulted_12m'].drop('defaulted_12m')\n",
    "    correlations = correlations.sort_values(key=abs, ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    correlations.plot(kind='barh', color=['red' if x < 0 else 'green' for x in correlations])\n",
    "    plt.title('Feature Correlations with Default Risk')\n",
    "    plt.xlabel('Correlation Coefficient')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop correlations:\")\n",
    "    for feature, corr in correlations.head(10).items():\n",
    "        print(f\"{feature:25}: {corr:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results Analysis (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model results if available\n",
    "results_files = {\n",
    "    'baseline': '../reports/metrics_baseline.json',\n",
    "    'fair': '../reports/metrics_fair.json'\n",
    "}\n",
    "\n",
    "fairness_files = {\n",
    "    'baseline': '../reports/fairness_baseline.json',\n",
    "    'fair': '../reports/fairness_fair.json'\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "fairness_results = {}\n",
    "\n",
    "for model_name, filepath in results_files.items():\n",
    "    if Path(filepath).exists():\n",
    "        with open(filepath) as f:\n",
    "            model_results[model_name] = json.load(f)\n",
    "        print(f\"‚úÖ Loaded {model_name} model metrics\")\n",
    "    else:\n",
    "        print(f\"‚ùå {model_name} model metrics not found\")\n",
    "\n",
    "for model_name, filepath in fairness_files.items():\n",
    "    if Path(filepath).exists():\n",
    "        with open(filepath) as f:\n",
    "            fairness_results[model_name] = json.load(f)\n",
    "        print(f\"‚úÖ Loaded {model_name} fairness metrics\")\n",
    "    else:\n",
    "        print(f\"‚ùå {model_name} fairness metrics not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_results:\n",
    "    print(\"üìä Model Performance Comparison:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    metrics_df = pd.DataFrame(model_results).T\n",
    "    display(metrics_df.round(4))\n",
    "    \n",
    "    # Plot comparison\n",
    "    if len(model_results) > 1:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        key_metrics = ['auc', 'accuracy', 'precision', 'recall']\n",
    "        \n",
    "        for i, metric in enumerate(key_metrics):\n",
    "            if metric in metrics_df.columns:\n",
    "                metrics_df[metric].plot(kind='bar', ax=axes[i], color=['skyblue', 'lightcoral'])\n",
    "                axes[i].set_title(f'{metric.upper()} Comparison')\n",
    "                axes[i].set_ylabel(metric.upper())\n",
    "                axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fairness_results:\n",
    "    print(\"‚öñÔ∏è Fairness Metrics Comparison:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Extract fairness metrics for comparison\n",
    "    fairness_summary = {}\n",
    "    \n",
    "    for model_name, results in fairness_results.items():\n",
    "        fairness_summary[model_name] = {}\n",
    "        \n",
    "        # Extract demographic parity and equalized odds\n",
    "        for attr in ['gender', 'region', 'role']:\n",
    "            if f'demographic_parity_{attr}' in results:\n",
    "                fairness_summary[model_name][f'dem_parity_{attr}'] = results[f'demographic_parity_{attr}']\n",
    "            if f'equalized_odds_{attr}' in results:\n",
    "                fairness_summary[model_name][f'eq_odds_{attr}'] = results[f'equalized_odds_{attr}']\n",
    "    \n",
    "    if fairness_summary:\n",
    "        fairness_df = pd.DataFrame(fairness_summary).T\n",
    "        display(fairness_df.round(4))\n",
    "        \n",
    "        # Plot fairness comparison\n",
    "        if len(fairness_summary) > 1 and not fairness_df.empty:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            # Demographic parity\n",
    "            dem_parity_cols = [col for col in fairness_df.columns if 'dem_parity' in col]\n",
    "            if dem_parity_cols:\n",
    "                fairness_df[dem_parity_cols].plot(kind='bar', ax=axes[0])\n",
    "                axes[0].set_title('Demographic Parity Difference')\n",
    "                axes[0].set_ylabel('Difference')\n",
    "                axes[0].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "                axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            \n",
    "            # Equalized odds\n",
    "            eq_odds_cols = [col for col in fairness_df.columns if 'eq_odds' in col]\n",
    "            if eq_odds_cols:\n",
    "                fairness_df[eq_odds_cols].plot(kind='bar', ax=axes[1])\n",
    "                axes[1].set_title('Equalized Odds Difference')\n",
    "                axes[1].set_ylabel('Difference')\n",
    "                axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "                axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nova Scores Analysis (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Nova scores if available\n",
    "scores_files = {\n",
    "    'baseline': '../data/partners_scores_baseline.csv',\n",
    "    'fair': '../data/partners_scores_fair.csv'\n",
    "}\n",
    "\n",
    "scores_data = {}\n",
    "\n",
    "for model_name, filepath in scores_files.items():\n",
    "    if Path(filepath).exists():\n",
    "        scores_data[model_name] = pd.read_csv(filepath)\n",
    "        print(f\"‚úÖ Loaded {model_name} Nova scores\")\n",
    "    else:\n",
    "        print(f\"‚ùå {model_name} Nova scores not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scores_data:\n",
    "    print(\"üìä Nova Scores Analysis:\")\n",
    "    \n",
    "    for model_name, data in scores_data.items():\n",
    "        if 'nova_score' in data.columns:\n",
    "            print(f\"\\n{model_name.upper()} MODEL:\")\n",
    "            print(f\"Nova Score Range: {data['nova_score'].min():.0f} - {data['nova_score'].max():.0f}\")\n",
    "            print(f\"Mean Nova Score: {data['nova_score'].mean():.1f}\")\n",
    "            print(f\"Std Nova Score: {data['nova_score'].std():.1f}\")\n",
    "            \n",
    "            # Score distribution by sensitive attributes\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            # Overall distribution\n",
    "            data['nova_score'].hist(bins=30, ax=axes[0], alpha=0.7, edgecolor='black')\n",
    "            axes[0].set_title(f'{model_name.title()} - Nova Score Distribution')\n",
    "            axes[0].set_xlabel('Nova Score')\n",
    "            axes[0].set_ylabel('Frequency')\n",
    "            \n",
    "            # By sensitive attributes\n",
    "            for i, attr in enumerate(sensitive_attrs):\n",
    "                if attr in data.columns and i < 3:\n",
    "                    sns.boxplot(data=data, x=attr, y='nova_score', ax=axes[i+1])\n",
    "                    axes[i+1].set_title(f'Nova Score by {attr.title()}')\n",
    "                    axes[i+1].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Score distribution by default status\n",
    "            if 'defaulted_12m' in data.columns:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                for default_status in [0, 1]:\n",
    "                    subset = data[data['defaulted_12m'] == default_status]\n",
    "                    plt.hist(subset['nova_score'], bins=30, alpha=0.7, \n",
    "                            label=f\"{'Defaulted' if default_status else 'Non-defaulted'}\")\n",
    "                \n",
    "                plt.title(f'{model_name.title()} - Nova Score by Default Status')\n",
    "                plt.xlabel('Nova Score')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.legend()\n",
    "                plt.grid(alpha=0.3)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nüìä Dataset Overview:\")\n",
    "    print(f\"‚Ä¢ Total partners: {len(df):,}\")\n",
    "    print(f\"‚Ä¢ Overall default rate: {df['defaulted_12m'].mean()*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüë• Demographics:\")\n",
    "    for attr in sensitive_attrs:\n",
    "        unique_vals = df[attr].nunique()\n",
    "        print(f\"‚Ä¢ {attr.title()}: {unique_vals} categories\")\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è Fairness Observations:\")\n",
    "    for attr in sensitive_attrs:\n",
    "        rates = df.groupby(attr)['defaulted_12m'].mean()\n",
    "        min_rate, max_rate = rates.min(), rates.max()\n",
    "        diff = max_rate - min_rate\n",
    "        print(f\"‚Ä¢ {attr.title()} default rate range: {min_rate*100:.1f}% - {max_rate*100:.1f}% (diff: {diff*100:.1f}pp)\")\n",
    "        if diff > 0.02:  # More than 2 percentage points\n",
    "            print(f\"  ‚ö†Ô∏è  Potential fairness concern detected\")\n",
    "\n",
    "if model_results:\n",
    "    print(f\"\\nü§ñ Model Performance:\")\n",
    "    for model_name, metrics in model_results.items():\n",
    "        auc = metrics.get('auc', 'N/A')\n",
    "        print(f\"‚Ä¢ {model_name.title()}: AUC = {auc}\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "print(f\"‚Ä¢ Monitor fairness metrics across all sensitive attributes\")\n",
    "print(f\"‚Ä¢ Consider additional bias mitigation techniques if needed\")\n",
    "print(f\"‚Ä¢ Validate model performance on holdout data\")\n",
    "print(f\"‚Ä¢ Implement continuous monitoring in production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Run the full pipeline**: `python run_project.py`\n",
    "2. **Analyze results**: Re-run this notebook after model training\n",
    "3. **Experiment**: Try different fairness mitigation strategies\n",
    "4. **Deploy**: Implement the Nova scoring system\n",
    "5. **Monitor**: Set up ongoing fairness and performance monitoring\n",
    "\n",
    "For more details, check the project README and documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
